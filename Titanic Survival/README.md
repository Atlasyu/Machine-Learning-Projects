# Machine Learing 101 Project: Titanic: Machine Learning from Disaster

Classification:
* RandomForestClassifier (random_state) works the best in this case.

Feature Selection:
* Avoid overfitting. 
* Better precting power in unknown dataset

Hyperparameter tuning:
* A little bit improvement in prediction

Couple tutorials:
* [A Journey through Titanic](https://www.kaggle.com/omarelgabry/a-journey-through-titanic)
* [How to score 0.8134 in Titanic Kaggle Challenge](http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html)


Summary:
* Titanic: Machine Learning from Disaster is a fairly easy machine learning project. 101 level.
* However, it's very difficult to pass the 80 mark in the LeaderBoard. The challenge here is to get past 80.
* Initially, I tried dozens different data preparing techniques, and wasn't able to reach the 80 mark. Very frustrating. The highest I could get was around 78.
* Random forest shows the best results in algorithms comparison. Random forest does not require data transformations. No need to standardize or normalize.
* Feature selection is necessary? Avoid overfitting, better predicting power?? 
* I started to focus on hyperparameter tuning. It took forever to tune the parameters. To my surprise, hyperparameter tuning was quite helpful, it bumped the score up to 79.4. The last few points are always the hardest. Took me a few days to bump up from around 77 to 79.426. Yet still fail to pass the 80. Dang!
